{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets as datasets\n",
    "from random import sample\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:  [784, 256, 64, 10]\n",
      "Learning Rate:  0.01\n",
      "Number of MiniBatch:  128\n",
      "Iterations:  10000\n"
     ]
    }
   ],
   "source": [
    "#Parameters - To be defined by user\n",
    "nClass = 10\n",
    "nHidden = [256, 64]\n",
    "nInput = 784\n",
    "layers = [nInput] + nHidden + [nClass]\n",
    "limit = 0.0001\n",
    "#Hyperparameters - To be tuned by the user\n",
    "learning_rate = 0.01\n",
    "nMiniBatch = 128\n",
    "nIter = 10000\n",
    "print(\"Layers: \", layers)\n",
    "print(\"Learning Rate: \", learning_rate)\n",
    "print(\"Number of MiniBatch: \", nMiniBatch)\n",
    "print(\"Iterations: \", nIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------data input function-----------------------------#\n",
    "def getDataset(name, nClass):\n",
    "    if name==\"mnist\":\n",
    "        dataset = datasets.mnist\n",
    "    (x_train, y_train),(x_test, y_test) = dataset.load_data()     #downloading and loading the dataset\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0             #normalizing the input data\n",
    "    x_train_flat = x_train.reshape(x_train.shape[0],-1).T         #making dataset suitable for input in Fully Connected layer\n",
    "    x_test_flat = x_test.reshape(x_test.shape[0],-1).T            #making dataset suitable for input in Fully Connected layer\n",
    "    y_train_onehot = np.eye(nClass)[y_train].T                    #converting to one hot vectors\n",
    "    y_test_onehot = np.eye(nClass)[y_test].T                      #converting to one hot vectors\n",
    "    return x_train_flat,x_test_flat,y_train_onehot,y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = getDataset(\"mnist\", nClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepfuzzy:\n",
    "    W = []\n",
    "    b = []\n",
    "    parameters = dict()\n",
    "    act = []\n",
    "    def __init__(self, layers, x_train, x_test, y_train, y_test, minibatch_size, load_weight = False learning_rate=0.01, iterations=100):\n",
    "        self.layers = layers\n",
    "        self.x_train_batch = x_train[:, :minibatch_size]\n",
    "        self.x_test = x_test\n",
    "        self.y_train_batch = y_train[:, :minibatch_size]\n",
    "        self.y_test = y_test\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.batch = minibatch_size\n",
    "        self.iter = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        if(load_weight = False):\n",
    "            self.initialize()\n",
    "        else:\n",
    "            self.loadWeights()\n",
    "    def initialize(self, initializer = 'random'):\n",
    "        if initiaizer = 'random':\n",
    "            for i in range(len(self.layers)-1):\n",
    "                self.W.append(np.random.rand(self.layers[i+1],self.layers[i])*0.02)\n",
    "                self.b.append(np.random.rand(self.layers[i+1],1))\n",
    "                assert(self.W[i].shape == (self.layers[i+1], self.layers[i]))\n",
    "                assert(self.b[i].shape == (self.layers[i+1], 1))\n",
    "        elif initializer == 'xavier':\n",
    "            pass\n",
    "        self.parameters['W'] = self.W\n",
    "        self.parameters['b'] = self.b\n",
    "    def forwardProp(self):\n",
    "        self.act=[]\n",
    "        self.act.append(self.x_train_batch)\n",
    "        for i in range(len(self.layers)-2):\n",
    "            z = np.dot(self.parameters['W'][i], self.act[-1])\n",
    "            self.act.append(relu(z + self.parameters['b'][i]))  #relu\n",
    "        self.act.append(softmax(np.dot(self.parameters['W'][len(self.layers)-2], self.act[-1])))\n",
    "    def compCost(self):\n",
    "        interm = np.dot(np.log(self.act[-1]).T,self.y_train_batch)\n",
    "        cost = -1.0/self.y_train_batch.shape[1]*np.sum(np.trace(interm))\n",
    "        return cost\n",
    "    def backProp(self):\n",
    "        m = self.y_train_batch.shape[1]\n",
    "        dZ = self.act[-1] - self.y_train_batch\n",
    "        dW = 1.0/m * np.dot(dZ, self.act[-2].T)\n",
    "        db = 1.0/m * np.dot(dZ, self.act[-2].T)\n",
    "        dA_prev = np.dot(self.parameters['W'][-1].T, dZ)\n",
    "        self.parameters['W'][-1] = self.parameters['W'][-1] - self.learning_rate*dW\n",
    "        self.parameters['b'][-1] = self.parameters['b'][-1] - self.learning_rate*db\n",
    "        for i in reversed(range(len(self.layers)-2)):\n",
    "            dA = dA_prev \n",
    "            dZ = linear_activation_backward(dA,self.act[i+1],\"relu\")\n",
    "            dW = 1.0/m * np.dot(dZ, self.act[i].T)\n",
    "            db = 1.0/m*  np.sum(np.array(dZ),axis=1,keepdims=True)\n",
    "            dA_prev = np.dot(self.parameters['W'][i].T, dZ)\n",
    "            self.parameters['W'][i] = self.parameters['W'][i] - self.learning_rate*dW\n",
    "            self.parameters['b'][i] = self.parameters['b'][i] - self.learning_rate*db\n",
    "    def check_accuracy(self, y, x):\n",
    "        mat = np.zeros([10,10])\n",
    "        m = y.shape[1]\n",
    "        buff_x = self.x_train_batch\n",
    "        self.x_train_batch = x[:,]\n",
    "        self.forwardProp()\n",
    "        pred = np.argmax(self.act[-1], axis = 0)\n",
    "        exp = np.argmax(y, axis = 0)\n",
    "        error = np.sum(exp!=pred)\n",
    "        self.x_train_batch = buff_x\n",
    "        for i in range(m):\n",
    "            mat[exp[i]][pred[i]] =  mat[exp[i]][pred[i]] + 1\n",
    "        # Calculate accuracy\n",
    "        return (m - error)/m * 100, mat\n",
    "    def train(self):\n",
    "        for i in range(self.iter):\n",
    "                if(i%2==0):\n",
    "                    idx = np.random.randint(self.x_train.shape[1], size=self.batch)\n",
    "                    self.x_train_batch = self.x_train[:,idx]\n",
    "                    self.y_train_batch = self.y_train[:,idx]\n",
    "                self.forwardProp()\n",
    "                cost = self.compCost()\n",
    "                self.backProp()\n",
    "                if(i%100 == 0):\n",
    "                    Accuracy, _ = self.check_accuracy(y_train,x_train)\n",
    "                    print(\"Accuracy: \", Accuracy)\n",
    "                    self.saveWeights()\n",
    "    def test(self):\n",
    "        self.forwardProp()\n",
    "        Accuracy, mat = self.check_accuracy(y_test,x_test)\n",
    "        print(\"Test Accuracy\", Accuracy )\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(mat)\n",
    "    def saveWeights(self):\n",
    "        np.save('W',self.parameters['W'])\n",
    "        np.save('b',self.parameters['b'])\n",
    "    def loadWeights(self):\n",
    "        try:\n",
    "            W = np.load('W.npy')\n",
    "            b = np.load('b.npy')\n",
    "            self.parameters['W'] = W\n",
    "            self.parameters['b'] = b\n",
    "        except:\n",
    "            print(\"Not able to load weights!\")\n",
    "            print(\"Initializing Weights...\")\n",
    "            self.initialize()\n",
    "            print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = deepfuzzy(layers, x_train, x_test, y_train, y_test, nMiniBatch, learning_rate=0.01, iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  9.863333333333333\n",
      "Accuracy:  9.863333333333333\n",
      "Accuracy:  10.218333333333334\n",
      "Accuracy:  10.218333333333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-5cf3f5dc7c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-74fc062e3816>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-74fc062e3816>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(self, y, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbuff_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-74fc062e3816>\u001b[0m in \u001b[0;36mforwardProp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 13.5\n"
     ]
    }
   ],
   "source": [
    "test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
