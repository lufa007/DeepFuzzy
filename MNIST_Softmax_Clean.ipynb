{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/ayushi/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/ayushi/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/ayushi/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libnvidia-fatbinaryloader.so.396.44: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libnvidia-fatbinaryloader.so.396.44: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-022420dfe9d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Data Input Pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/ayushi/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/ayushi/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/ayushi/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libnvidia-fatbinaryloader.so.396.44: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "#Data Input Pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "from random import sample\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Input Pipeline\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train_flat = x_train.reshape(x_train.shape[0],-1).T\n",
    "x_test_flat = x_test.reshape(x_test.shape[0],-1).T\n",
    "y_train_onehot = np.eye(nClass)[y_train].T\n",
    "y_test_onehot = np.eye(nClass)[y_test].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nHidden = [256, 64]\n",
    "learning_rate = 0.0001\n",
    "nMiniBatch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:  [784, 256, 64, 10]\n",
      "Learning Rate:  0.0001\n",
      "Number of MiniBatch:  128\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "nClass = 10\n",
    "nInput = [784]\n",
    "nOutput = [nClass]\n",
    "layers = nInput + nHidden + nOutput\n",
    "limit = 0.0001\n",
    "print(\"Layers: \", layers)\n",
    "print(\"Learning Rate: \", learning_rate)\n",
    "print(\"Number of MiniBatch: \", nMiniBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_10input_onehot',  y_train_onehot[:,[1,3,5,7,9,11,13,15,17,19]])  \n",
    "np.save('x_10input_flat',  x_train_flat[:,[1,3,5,7,9,11,13,15,17,19]])\n",
    "np.save('y_10test_onehot',  y_test_onehot[:,[3,2,1,18,4,8,11,0,61,7]])  \n",
    "np.save('x_10test_flat',  x_test_flat[:,[3,2,1,18,4,8,11,0,61,7]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist10():\n",
    "    x_train_flat = np.load(\"x_10input_flat.npy\")\n",
    "    y_train_onehot = np.load(\"y_10input_onehot.npy\")\n",
    "    y_test_onehot = np.load('y_10test_onehot.npy')\n",
    "    x_test_flat = np.load('x_10test_flat.npy')\n",
    "    return x_train_flat, y_train_onehot, y_test_onehot, x_test_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = x_train_flat.shape[1]\n",
    "# x_train_flat, y_train_onehot, y_test_onehot, x_test_flat = load_mnist10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepfuzzy:\n",
    "    W = []\n",
    "    b = []\n",
    "    parameters = dict()\n",
    "    act = []\n",
    "    def __init__(self, layers, test_data, train_data, y_train_onehot, y_test_onehot, no_of_examples, iterations):\n",
    "        self.layers = layers\n",
    "        self.test_data = test_data\n",
    "        self.tdx = train_data\n",
    "        self.tdy = y_train_onehot\n",
    "        self.batch = no_of_examples\n",
    "        self.train_data = train_data[:, :no_of_examples]\n",
    "        #print(self.train_data.shape)\n",
    "        print(\"train_data\",self.train_data.shape)\n",
    "        self.y_train_onehot = y_train_onehot[:,:no_of_examples]\n",
    "        self.y_test_onehot = y_test_onehot\n",
    "        print(\"train_onehot\",self.y_train_onehot.shape)\n",
    "        self.iter = iterations\n",
    "        initialize(self, 'random')\n",
    "    def train(self):\n",
    "        for i in range(self.iter):\n",
    "                if(i%2==0):\n",
    "                    idx = np.random.randint(self.tdx.shape[1], size=self.batch)\n",
    "                    self.train_data = np.array(self.tdx[:,idx])\n",
    "                    self.y_train_onehot = self.tdy[:,idx]\n",
    "#                     print(self.train_data)\n",
    "                forwardProptrain(self)\n",
    "                compCosttrain(self)\n",
    "                #print(self.act[-1])\n",
    "                #print(self.y_train_onehot)\n",
    "                backProp(self)\n",
    "#                 if(i%100 == 0):\n",
    "#                     self.saveWeights()\n",
    "    def test(self):\n",
    "        forwardProptest(self)\n",
    "        compCosttest(self)\n",
    "    def saveWeights(self):\n",
    "        np.save('W.npy',  self.parameters['W'])  \n",
    "        np.save('b.npy', self.parameters['b'])\n",
    "        my_dict_back = np.load('my_dict.npy')\n",
    "        \n",
    "    def loadWeights(self):\n",
    "        self.W = np.load('W.npy')\n",
    "        self.b = np.load('b.npy')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(self, initializer = 'random'):\n",
    "        #parameters = dict()\n",
    "        W = []\n",
    "        b = []\n",
    "        #np.random.seed(1)\n",
    "        for i in range(len(self.layers)-1):\n",
    "            W.append(np.random.rand(self.layers[i+1],self.layers[i])*0.02)\n",
    "            b.append(np.random.rand(self.layers[i+1],1))\n",
    "            assert(W[i].shape == (self.layers[i+1], self.layers[i]))\n",
    "            assert(b[i].shape == (self.layers[i+1], 1))\n",
    "            \n",
    "        self.parameters['W'] = W\n",
    "        self.parameters['b'] = b\n",
    "    \n",
    "        #print(\"w\", W)\n",
    "        #print(\"b\", self.parameters['b'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProptrain(self):\n",
    "    self.act=[]\n",
    "    self.act.append(self.train_data)\n",
    "    for i in range(len(self.layers)-2):\n",
    "        z = np.dot(self.parameters['W'][i], self.act[-1])\n",
    "        #print(\"z\",z)\n",
    "        #print(\"self.parameter[b]\", self.parameters['b'][i].shape)\n",
    "        self.act.append(relu(z + self.parameters['b'][i]))  #relu\n",
    "    self.act.append(softmax(np.dot(self.parameters['W'][len(self.layers)-2], self.act[-1])))\n",
    "#     print(\"final_layer = \", self.act[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProptest(self):\n",
    "    self.act=[]\n",
    "    self.act.append(self.test_data)\n",
    "    for i in range(len(self.layers)-2):\n",
    "        z = np.dot(self.parameters['W'][i], self.act[-1])\n",
    "        #print(\"z\",z)\n",
    "        #print(\"self.parameter[b]\", self.parameters['b'][i].shape)\n",
    "        self.act.append(relu(z + self.parameters['b'][i]))  #relu\n",
    "    self.act.append(softmax(np.dot(self.parameters['W'][len(self.layers)-2], self.act[-1])))\n",
    "#     print(\"final_layer = \", self.act[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compCosttrain(self):\n",
    "    #print(\"y-train-oneshots_shape \", self.y_train_onehot.shape, self.act[-1].T)\n",
    "    #print((1-self.y_train_onehot),np.log(1-self.act[-1]).T)\n",
    "    interm = np.dot(np.log(self.act[-1]).T,self.y_train_onehot)\n",
    "#     print(\"interm.shape = \", interm.shape)\n",
    "    cost = -1.0/self.y_train_onehot.shape[1]*np.sum(np.trace(interm))\n",
    "    print(cost)\n",
    "#     print(\"expected = \", self.y_train_onehot)\n",
    "#     print(\"got = \", self.act[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compCosttest(self):\n",
    "    #print(\"y-train-oneshots_shape \", self.y_train_onehot.shape, self.act[-1].T)\n",
    "    #print((1-self.y_train_onehot),np.log(1-self.act[-1]).T)\n",
    "    interm = np.dot(np.log(self.act[-1]).T,self.y_train_onehot)\n",
    "#     print(\"interm.shape = \", interm.shape)\n",
    "    cost = -1.0/self.y_train_onehot.shape[1]*np.sum(np.trace(interm))\n",
    "    print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(self):\n",
    "    dZ = self.act[-1] - self.y_train_onehot\n",
    "    m = self.y_train_onehot.shape[1]\n",
    "    dW = 1.0/m * np.dot(dZ, self.act[-2].T)\n",
    "    db = 1.0/m * np.dot(dZ, self.act[-2].T)\n",
    "#     dAL = -np.divide(self.y_train_onehot, self.act[-1])+np.divide(1-self.y_train_onehot, 1-self.act[-1])\n",
    "    \n",
    "    dA_prev = np.dot(self.parameters['W'][-1].T, dZ)\n",
    "    self.parameters['W'][-1] = self.parameters['W'][-1] - learning_rate*dW\n",
    "    self.parameters['b'][-1] = self.parameters['b'][-1] - learning_rate*db\n",
    "    \n",
    "    for i in reversed(range(len(self.layers)-2)):\n",
    "        dA = dA_prev \n",
    "        dZ = linear_activation_backward(dA,self.act[i+1],\"relu\")\n",
    "        #print(\"dZ\",dZ)\n",
    "        dW = 1.0/m * np.dot(dZ, self.act[i].T)\n",
    "        #print(\"dW\",dW)\n",
    "        db = 1.0/m*  np.sum(np.array(dZ),axis=1,keepdims=True)\n",
    "#         print(\"db\",db.shape)\n",
    "        #print(\"m\",m)\n",
    "        dA_prev = np.dot(self.parameters['W'][i].T, dZ)\n",
    "        self.parameters['W'][i] = self.parameters['W'][i] - learning_rate*dW\n",
    "        self.parameters['b'][i] = self.parameters['b'][i] - learning_rate*db\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA,cache,activation):\n",
    "    if(activation==\"sigmoid\"):\n",
    "        act =  cache \n",
    "        #print(\"dA\",dA)\n",
    "        #print(\"cache\", cache)\n",
    "        #return dA*act*(1-act)\n",
    "        return np.multiply(np.multiply(dA, act), 1-act)\n",
    "    if(activation==\"relu\"):\n",
    "        act = cache\n",
    "        act[act>0] = 1\n",
    "        act[act<0] = 0\n",
    "        return np.multiply(dA, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_train():\n",
    "    y = test.tdy\n",
    "    test.train_data = test.tdx[:,]\n",
    "    test.y_train_onehot = test.tdy[:,:100]\n",
    "#     imshow(test.train_data[:,1].reshape(28,28))\n",
    "    \n",
    "#     print(test.train_data[:,0])\n",
    "    print(test.y_train_onehot[:,:5])\n",
    "    m = y.shape[1]\n",
    "    forwardProptrain(test)\n",
    "    print(\"test.act[1] = \",test.act[1][:,:5])\n",
    "    print(\"shape = \", test.act[1][:,0].shape)\n",
    "    print((test.act[1][:,0]==1).all())\n",
    "#     imshow(test.act[1][:,0].reshape(50,50))\n",
    "#     imshow(test.parameters['W'][1])\n",
    "    \n",
    "#     print(test.act[-1])\n",
    "    y_hat = np.argmax(test.act[-1], axis = 0)\n",
    "#     print(\"hat = \",y_hat)\n",
    "#     print(\"y = \",y)\n",
    "    pred = y_hat\n",
    "    exp = np.argmax(y, axis = 0)\n",
    "    error = np.sum(exp!=pred)\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros([10,10])\n",
    "def check_accuracy_test():\n",
    "    y = test.y_test_onehot\n",
    "    test.train_data = test.test_data[:,]\n",
    "    test.y_train_onehot = test.y_test_onehot[:,:100]\n",
    "#     imshow(test.train_data[:,1].reshape(28,28))\n",
    "    \n",
    "#     print(test.train_data[:,0])\n",
    "    print(test.y_train_onehot)\n",
    "    m = y.shape[1]\n",
    "    print(m)\n",
    "    forwardProptrain(test)\n",
    "#     print(\"test.act[1] = \",test.act[1][:,:5])\n",
    "#     print(\"shape = \", test.act[1][:,0].shape)\n",
    "#     print((test.act[1][:,0]==1).all())\n",
    "#     imshow(test.act[1][:,0].reshape(50,50))\n",
    "#     imshow(test.parameters['W'][1])\n",
    "    \n",
    "#     print(test.act[-1].shape)\n",
    "    y_hat = np.argmax(test.act[-1], axis = 0)\n",
    "    \n",
    "#     print(\"hat = \",y_hat)\n",
    "#     print(\"y = \",y)\n",
    "    pred = y_hat\n",
    "    exp = np.argmax(y, axis = 0)\n",
    "    p = exp!=pred\n",
    "#     print(p)\n",
    "    error = np.sum(exp!=pred)\n",
    "    for i in range(m):\n",
    "        mat[exp[i]][pred[i]] =  mat[exp[i]][pred[i]] + 1\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fff5d40e7fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_onehot1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepfuzzy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_onehot1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "y_train_onehot1 = y_train_onehot[:,[1]*5]\n",
    "test = deepfuzzy(layers,x_test_flat,x_train_flat,y_train_onehot,y_test_onehot, 128, 100000)\n",
    "print(y_train_onehot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a46339771980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f68bf5458eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
