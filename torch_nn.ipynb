{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use this on google colaboratory\n",
    "try:\n",
    "    from nn_fuzzy\n",
    "except:\n",
    "    !rm -f -r DeepFuzzy\n",
    "    !git clone https://github.com/tanishqjasoria/DeepFuzzy.git\n",
    "    import sys\n",
    "    sys.path.insert(0,'/content/DeepFuzzy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorflow.keras.datasets as datasets\n",
    "from torch_dataload import MyDataset\n",
    "import nn_fuzzy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:  [784, 256, 10]\n",
      "Learning Rate:  0.01\n",
      "Number of MiniBatch:  128\n",
      "Iterations:  10000\n",
      "Layers:  [2352, 256, 10]\n",
      "Learning Rate:  0.01\n",
      "Number of MiniBatch:  128\n",
      "Iterations:  10000\n",
      "Layers:  [39, 8, 2]\n",
      "Learning Rate:  0.01\n",
      "Number of MiniBatch:  16\n",
      "Iterations:  10000\n"
     ]
    }
   ],
   "source": [
    "#Parameters - To be defined by user\n",
    "nClass = 10\n",
    "nHidden = [256]\n",
    "nInput = 784\n",
    "layers = [nInput] + nHidden + [nClass]\n",
    "limit = 0.0001\n",
    "#Hyperparameters - To be tuned by the user\n",
    "learning_rate = 0.01\n",
    "nMiniBatch = 128\n",
    "nIter = 10000\n",
    "print(\"Layers: \", layers)\n",
    "print(\"Learning Rate: \", learning_rate)\n",
    "print(\"Number of MiniBatch: \", nMiniBatch)\n",
    "print(\"Iterations: \", nIter)\n",
    "\n",
    "#Parameters (for fuzzy)- To be defined by user\n",
    "nClass_fuzzy = 10\n",
    "nHidden_fuzzy = [256]\n",
    "nInput_fuzzy = 784 * 3\n",
    "layers_fuzzy = [nInput_fuzzy] + nHidden_fuzzy + [nClass_fuzzy]\n",
    "limit = 0.0001\n",
    "#Hyperparameters - To be tuned by the user\n",
    "learning_rate = 0.01\n",
    "nMiniBatch = 128\n",
    "nIter = 10000\n",
    "print(\"Layers: \", layers_fuzzy)\n",
    "print(\"Learning Rate: \", learning_rate)\n",
    "print(\"Number of MiniBatch: \", nMiniBatch)\n",
    "print(\"Iterations: \", nIter)\n",
    "\n",
    "#Parameters (for heart)- To be defined by user\n",
    "nClass_heart = 2\n",
    "nHidden_heart = [8]\n",
    "nInput_heart = 13 * 3\n",
    "layers_heart = [nInput_heart] + nHidden_heart + [nClass_heart]\n",
    "limit = 0.0001\n",
    "#Hyperparameters - To be tuned by the user\n",
    "learning_rate = 0.01\n",
    "nMiniBatch = 16\n",
    "nIter = 10000\n",
    "print(\"Layers: \", layers_heart)\n",
    "print(\"Learning Rate: \", learning_rate)\n",
    "print(\"Number of MiniBatch: \", nMiniBatch)\n",
    "print(\"Iterations: \", nIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(129, 784)\n"
     ]
    }
   ],
   "source": [
    "#-------data input function-----------------------------#\n",
    "def getDataset(name, nClass):\n",
    "    if name==\"mnist\":\n",
    "        dataset = datasets.mnist\n",
    "    (x_train, y_train),(x_test, y_test) = dataset.load_data()     #downloading and loading the dataset\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0             #normalizing the input data\n",
    "    x_train_flat = x_train.reshape(x_train.shape[0],-1)         #making dataset suitable for input in Fully Connected layer\n",
    "    x_test_flat = x_test.reshape(x_test.shape[0],-1)          #making dataset suitable for input in Fully Connected layer\n",
    "    y_train_onehot = np.eye(nClass)[y_train]                    #converting to one hot vectors\n",
    "    y_test_onehot = np.eye(nClass)[y_test]                     #converting to one hot vectors\n",
    "    print(x_train_flat.shape)\n",
    "    print(y_train_onehot.shape)\n",
    "    x_train_batch = np.array_split(x_train_flat, int(60000/128))\n",
    "    print(x_train_batch[2].shape)\n",
    "    return x_train_flat,x_test_flat,y_train_onehot,y_test_onehot\n",
    "\n",
    "x_train, x_test, y_train, y_test = getDataset(\"mnist\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fuzzify - x_train : 0.2614285945892334\n",
      "Time taken to fuzzify - x_test : 0.38419532775878906\n",
      "(10, 784)\n",
      "(10, 784)\n",
      "Time taken to fuzzify - y_train : 0.03492021560668945\n",
      "Time taken to fuzzify - y_train : 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "x_train_fuzzy, x_test_fuzzy, y_train_fuzzy, y_test_fuzzy = nn_fuzzy.fuzzify_dataset(x_train[:100], x_test[:100], y_train, y_test, cnn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fuzzy = np.load('x_train_fuzzy.npy')\n",
    "x_test_fuzzy = np.load('x_test_fuzzy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fuzzy = x_train_fuzzy.reshape(-1, 3, 28, 28)\n",
    "x_test_fuzzy = x_test_fuzzy.reshape(-1, 3, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa02c208710>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.21928273e-04, 1.03993395e-02, 3.34235633e-04, 1.18879147e-03,\n",
       "       5.75091298e-04, 5.63407240e-02, 1.08669372e-03, 3.89759862e-05,\n",
       "       6.87094821e-04, 4.30051944e-03])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "plt.imshow(x_train[index].reshape(28,28), cmap='Greys')\n",
    "y_train_fuzzy[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.21928273e-04, 1.03993395e-02, 3.34235633e-04, 1.18879147e-03,\n",
       "       5.75091298e-04, 5.63407240e-02, 1.08669372e-03, 3.89759862e-05,\n",
       "       6.87094821e-04, 4.30051944e-03])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_fuzzy[index][0].reshape(28,28), cmap='Greys')\n",
    "y_train_fuzzy[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12169636e-01, 4.73381039e-04, 2.36646506e-04, 4.42059570e-04,\n",
       "       5.07382296e-04, 8.77647617e-05, 7.50954992e-04, 1.47326837e-03,\n",
       "       2.85696830e-04, 1.30160031e-03])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_fuzzy[index][1].reshape(28,28), cmap='Greys')\n",
    "y_train_fuzzy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12169636e-01, 4.73381039e-04, 2.36646506e-04, 4.42059570e-04,\n",
       "       5.07382296e-04, 8.77647617e-05, 7.50954992e-04, 1.47326837e-03,\n",
       "       2.85696830e-04, 1.30160031e-03])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_fuzzy[index][2].reshape(28,28), cmap='Greys')\n",
    "y_train_fuzzy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = MyDataset(x_train, x_test, y_train, y_test, train=True)\n",
    "trainset = MyDataset(x_train_fuzzy, x_test_fuzzy, y_train, y_test, train=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# testset = MyDataset(x_train, x_test, y_train, y_test, train=False)\n",
    "testset = MyDataset(x_train_fuzzy, x_test_fuzzy, y_train, y_test, train=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 3, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.003\n",
      "[1,    40] loss: 0.003\n",
      "[1,    60] loss: 0.003\n",
      "[1,    80] loss: 0.003\n",
      "[1,   100] loss: 0.003\n",
      "[1,   120] loss: 0.003\n",
      "[1,   140] loss: 0.003\n",
      "[1,   160] loss: 0.003\n",
      "[1,   180] loss: 0.003\n",
      "[1,   200] loss: 0.003\n",
      "[1,   220] loss: 0.003\n",
      "[1,   240] loss: 0.003\n",
      "[1,   260] loss: 0.003\n",
      "[1,   280] loss: 0.003\n",
      "[1,   300] loss: 0.003\n",
      "[1,   320] loss: 0.003\n",
      "[1,   340] loss: 0.003\n",
      "[1,   360] loss: 0.003\n",
      "[1,   380] loss: 0.003\n",
      "[1,   400] loss: 0.003\n",
      "[1,   420] loss: 0.003\n",
      "[1,   440] loss: 0.003\n",
      "[1,   460] loss: 0.003\n",
      "[1,   480] loss: 0.003\n",
      "[1,   500] loss: 0.003\n",
      "[1,   520] loss: 0.003\n",
      "[1,   540] loss: 0.003\n",
      "[1,   560] loss: 0.003\n",
      "[1,   580] loss: 0.003\n",
      "[1,   600] loss: 0.003\n",
      "[1,   620] loss: 0.003\n",
      "[1,   640] loss: 0.003\n",
      "[1,   660] loss: 0.003\n",
      "[1,   680] loss: 0.003\n",
      "[1,   700] loss: 0.003\n",
      "[1,   720] loss: 0.003\n",
      "[1,   740] loss: 0.003\n",
      "[1,   760] loss: 0.003\n",
      "[1,   780] loss: 0.003\n",
      "[1,   800] loss: 0.003\n",
      "[1,   820] loss: 0.003\n",
      "[1,   840] loss: 0.003\n",
      "[1,   860] loss: 0.003\n",
      "[1,   880] loss: 0.003\n",
      "[1,   900] loss: 0.003\n",
      "[1,   920] loss: 0.003\n",
      "[2,    20] loss: 0.003\n",
      "[2,    40] loss: 0.003\n",
      "[2,    60] loss: 0.003\n",
      "[2,    80] loss: 0.003\n",
      "[2,   100] loss: 0.003\n",
      "[2,   120] loss: 0.003\n",
      "[2,   140] loss: 0.003\n",
      "[2,   160] loss: 0.003\n",
      "[2,   180] loss: 0.003\n",
      "[2,   200] loss: 0.003\n",
      "[2,   220] loss: 0.003\n",
      "[2,   240] loss: 0.003\n",
      "[2,   260] loss: 0.003\n",
      "[2,   280] loss: 0.003\n",
      "[2,   300] loss: 0.003\n",
      "[2,   320] loss: 0.003\n",
      "[2,   340] loss: 0.003\n",
      "[2,   360] loss: 0.003\n",
      "[2,   380] loss: 0.003\n",
      "[2,   400] loss: 0.003\n",
      "[2,   420] loss: 0.003\n",
      "[2,   440] loss: 0.003\n",
      "[2,   460] loss: 0.003\n",
      "[2,   480] loss: 0.003\n",
      "[2,   500] loss: 0.003\n",
      "[2,   520] loss: 0.003\n",
      "[2,   540] loss: 0.003\n",
      "[2,   560] loss: 0.003\n",
      "[2,   580] loss: 0.003\n",
      "[2,   600] loss: 0.003\n",
      "[2,   620] loss: 0.003\n",
      "[2,   640] loss: 0.003\n",
      "[2,   660] loss: 0.003\n",
      "[2,   680] loss: 0.003\n",
      "[2,   700] loss: 0.003\n",
      "[2,   720] loss: 0.003\n",
      "[2,   740] loss: 0.003\n",
      "[2,   760] loss: 0.003\n",
      "[2,   780] loss: 0.003\n",
      "[2,   800] loss: 0.003\n",
      "[2,   820] loss: 0.003\n",
      "[2,   840] loss: 0.003\n",
      "[2,   860] loss: 0.003\n",
      "[2,   880] loss: 0.003\n",
      "[2,   900] loss: 0.003\n",
      "[2,   920] loss: 0.003\n",
      "[3,    20] loss: 0.003\n",
      "[3,    40] loss: 0.003\n",
      "[3,    60] loss: 0.003\n",
      "[3,    80] loss: 0.003\n",
      "[3,   100] loss: 0.003\n",
      "[3,   120] loss: 0.003\n",
      "[3,   140] loss: 0.003\n",
      "[3,   160] loss: 0.003\n",
      "[3,   180] loss: 0.003\n",
      "[3,   200] loss: 0.003\n",
      "[3,   220] loss: 0.003\n",
      "[3,   240] loss: 0.003\n",
      "[3,   260] loss: 0.003\n",
      "[3,   280] loss: 0.003\n",
      "[3,   300] loss: 0.003\n",
      "[3,   320] loss: 0.003\n",
      "[3,   340] loss: 0.003\n",
      "[3,   360] loss: 0.003\n",
      "[3,   380] loss: 0.003\n",
      "[3,   400] loss: 0.003\n",
      "[3,   420] loss: 0.003\n",
      "[3,   440] loss: 0.003\n",
      "[3,   460] loss: 0.003\n",
      "[3,   480] loss: 0.003\n",
      "[3,   500] loss: 0.003\n",
      "[3,   520] loss: 0.003\n",
      "[3,   540] loss: 0.003\n",
      "[3,   560] loss: 0.003\n",
      "[3,   580] loss: 0.003\n",
      "[3,   600] loss: 0.003\n",
      "[3,   620] loss: 0.003\n",
      "[3,   640] loss: 0.003\n",
      "[3,   660] loss: 0.003\n",
      "[3,   680] loss: 0.003\n",
      "[3,   700] loss: 0.003\n",
      "[3,   720] loss: 0.003\n",
      "[3,   740] loss: 0.003\n",
      "[3,   760] loss: 0.003\n",
      "[3,   780] loss: 0.003\n",
      "[3,   800] loss: 0.003\n",
      "[3,   820] loss: 0.003\n",
      "[3,   840] loss: 0.003\n",
      "[3,   860] loss: 0.003\n",
      "[3,   880] loss: 0.003\n",
      "[3,   900] loss: 0.003\n",
      "[3,   920] loss: 0.003\n",
      "[4,    20] loss: 0.003\n",
      "[4,    40] loss: 0.003\n",
      "[4,    60] loss: 0.003\n",
      "[4,    80] loss: 0.003\n",
      "[4,   100] loss: 0.003\n",
      "[4,   120] loss: 0.003\n",
      "[4,   140] loss: 0.003\n",
      "[4,   160] loss: 0.003\n",
      "[4,   180] loss: 0.003\n",
      "[4,   200] loss: 0.003\n",
      "[4,   220] loss: 0.003\n",
      "[4,   240] loss: 0.003\n",
      "[4,   260] loss: 0.003\n",
      "[4,   280] loss: 0.003\n",
      "[4,   300] loss: 0.003\n",
      "[4,   320] loss: 0.003\n",
      "[4,   340] loss: 0.003\n",
      "[4,   360] loss: 0.003\n",
      "[4,   380] loss: 0.003\n",
      "[4,   400] loss: 0.003\n",
      "[4,   420] loss: 0.003\n",
      "[4,   440] loss: 0.003\n",
      "[4,   460] loss: 0.003\n",
      "[4,   480] loss: 0.003\n",
      "[4,   500] loss: 0.003\n",
      "[4,   520] loss: 0.003\n",
      "[4,   540] loss: 0.003\n",
      "[4,   560] loss: 0.003\n",
      "[4,   580] loss: 0.003\n",
      "[4,   600] loss: 0.003\n",
      "[4,   620] loss: 0.003\n",
      "[4,   640] loss: 0.003\n",
      "[4,   660] loss: 0.003\n",
      "[4,   680] loss: 0.003\n",
      "[4,   700] loss: 0.003\n",
      "[4,   720] loss: 0.003\n",
      "[4,   740] loss: 0.003\n",
      "[4,   760] loss: 0.003\n",
      "[4,   780] loss: 0.003\n",
      "[4,   800] loss: 0.003\n",
      "[4,   820] loss: 0.003\n",
      "[4,   840] loss: 0.003\n",
      "[4,   860] loss: 0.003\n",
      "[4,   880] loss: 0.003\n",
      "[4,   900] loss: 0.003\n",
      "[4,   920] loss: 0.003\n",
      "[5,    20] loss: 0.003\n",
      "[5,    40] loss: 0.003\n",
      "[5,    60] loss: 0.003\n",
      "[5,    80] loss: 0.003\n",
      "[5,   100] loss: 0.003\n",
      "[5,   120] loss: 0.003\n",
      "[5,   140] loss: 0.003\n",
      "[5,   160] loss: 0.003\n",
      "[5,   180] loss: 0.003\n",
      "[5,   200] loss: 0.003\n",
      "[5,   220] loss: 0.003\n",
      "[5,   240] loss: 0.003\n",
      "[5,   260] loss: 0.003\n",
      "[5,   280] loss: 0.003\n",
      "[5,   300] loss: 0.003\n",
      "[5,   320] loss: 0.003\n",
      "[5,   340] loss: 0.003\n",
      "[5,   360] loss: 0.003\n",
      "[5,   380] loss: 0.003\n",
      "[5,   400] loss: 0.003\n",
      "[5,   420] loss: 0.003\n",
      "[5,   440] loss: 0.003\n",
      "[5,   460] loss: 0.003\n",
      "[5,   480] loss: 0.003\n",
      "[5,   500] loss: 0.003\n",
      "[5,   520] loss: 0.003\n",
      "[5,   540] loss: 0.003\n",
      "[5,   560] loss: 0.003\n",
      "[5,   580] loss: 0.003\n",
      "[5,   600] loss: 0.003\n",
      "[5,   620] loss: 0.003\n",
      "[5,   640] loss: 0.003\n",
      "[5,   660] loss: 0.003\n",
      "[5,   680] loss: 0.003\n",
      "[5,   700] loss: 0.003\n",
      "[5,   720] loss: 0.002\n",
      "[5,   740] loss: 0.002\n",
      "[5,   760] loss: 0.002\n",
      "[5,   780] loss: 0.002\n",
      "[5,   800] loss: 0.002\n",
      "[5,   820] loss: 0.002\n",
      "[5,   840] loss: 0.002\n",
      "[5,   860] loss: 0.002\n",
      "[5,   880] loss: 0.002\n",
      "[5,   900] loss: 0.002\n",
      "[5,   920] loss: 0.002\n",
      "[6,    20] loss: 0.002\n",
      "[6,    40] loss: 0.002\n",
      "[6,    60] loss: 0.002\n",
      "[6,    80] loss: 0.002\n",
      "[6,   100] loss: 0.002\n",
      "[6,   120] loss: 0.002\n",
      "[6,   140] loss: 0.002\n",
      "[6,   160] loss: 0.002\n",
      "[6,   180] loss: 0.002\n",
      "[6,   200] loss: 0.002\n",
      "[6,   220] loss: 0.002\n",
      "[6,   240] loss: 0.002\n",
      "[6,   260] loss: 0.002\n",
      "[6,   280] loss: 0.002\n",
      "[6,   300] loss: 0.002\n",
      "[6,   320] loss: 0.002\n",
      "[6,   340] loss: 0.002\n",
      "[6,   360] loss: 0.002\n",
      "[6,   380] loss: 0.002\n",
      "[6,   400] loss: 0.002\n",
      "[6,   420] loss: 0.002\n",
      "[6,   440] loss: 0.002\n",
      "[6,   460] loss: 0.002\n",
      "[6,   480] loss: 0.002\n",
      "[6,   500] loss: 0.002\n",
      "[6,   520] loss: 0.002\n",
      "[6,   540] loss: 0.002\n",
      "[6,   560] loss: 0.002\n",
      "[6,   580] loss: 0.002\n",
      "[6,   600] loss: 0.002\n",
      "[6,   620] loss: 0.002\n",
      "[6,   640] loss: 0.002\n",
      "[6,   660] loss: 0.002\n",
      "[6,   680] loss: 0.002\n",
      "[6,   700] loss: 0.002\n",
      "[6,   720] loss: 0.002\n",
      "[6,   740] loss: 0.002\n",
      "[6,   760] loss: 0.002\n",
      "[6,   780] loss: 0.002\n",
      "[6,   800] loss: 0.002\n",
      "[6,   820] loss: 0.002\n",
      "[6,   840] loss: 0.002\n",
      "[6,   860] loss: 0.002\n",
      "[6,   880] loss: 0.002\n",
      "[6,   900] loss: 0.002\n",
      "[6,   920] loss: 0.001\n",
      "[7,    20] loss: 0.002\n",
      "[7,    40] loss: 0.001\n",
      "[7,    60] loss: 0.001\n",
      "[7,    80] loss: 0.001\n",
      "[7,   100] loss: 0.002\n",
      "[7,   120] loss: 0.001\n",
      "[7,   140] loss: 0.001\n",
      "[7,   160] loss: 0.001\n",
      "[7,   180] loss: 0.001\n",
      "[7,   200] loss: 0.001\n",
      "[7,   220] loss: 0.001\n",
      "[7,   240] loss: 0.001\n",
      "[7,   260] loss: 0.001\n",
      "[7,   280] loss: 0.001\n",
      "[7,   300] loss: 0.001\n",
      "[7,   320] loss: 0.001\n",
      "[7,   340] loss: 0.001\n",
      "[7,   360] loss: 0.001\n",
      "[7,   380] loss: 0.001\n",
      "[7,   400] loss: 0.001\n",
      "[7,   420] loss: 0.001\n",
      "[7,   440] loss: 0.001\n",
      "[7,   460] loss: 0.001\n",
      "[7,   480] loss: 0.001\n",
      "[7,   500] loss: 0.001\n",
      "[7,   520] loss: 0.001\n",
      "[7,   540] loss: 0.001\n",
      "[7,   560] loss: 0.001\n",
      "[7,   580] loss: 0.001\n",
      "[7,   600] loss: 0.001\n",
      "[7,   620] loss: 0.001\n",
      "[7,   640] loss: 0.001\n",
      "[7,   660] loss: 0.001\n",
      "[7,   680] loss: 0.001\n",
      "[7,   700] loss: 0.001\n",
      "[7,   720] loss: 0.001\n",
      "[7,   740] loss: 0.001\n",
      "[7,   760] loss: 0.001\n",
      "[7,   780] loss: 0.001\n",
      "[7,   800] loss: 0.001\n",
      "[7,   820] loss: 0.001\n",
      "[7,   840] loss: 0.001\n",
      "[7,   860] loss: 0.001\n",
      "[7,   880] loss: 0.001\n",
      "[7,   900] loss: 0.001\n",
      "[7,   920] loss: 0.001\n",
      "[8,    20] loss: 0.001\n",
      "[8,    40] loss: 0.001\n",
      "[8,    60] loss: 0.001\n",
      "[8,    80] loss: 0.001\n",
      "[8,   100] loss: 0.001\n",
      "[8,   120] loss: 0.001\n",
      "[8,   140] loss: 0.001\n",
      "[8,   160] loss: 0.001\n",
      "[8,   180] loss: 0.001\n",
      "[8,   200] loss: 0.001\n",
      "[8,   220] loss: 0.001\n",
      "[8,   240] loss: 0.001\n",
      "[8,   260] loss: 0.001\n",
      "[8,   280] loss: 0.001\n",
      "[8,   300] loss: 0.001\n",
      "[8,   320] loss: 0.001\n",
      "[8,   340] loss: 0.001\n",
      "[8,   360] loss: 0.001\n",
      "[8,   380] loss: 0.001\n",
      "[8,   400] loss: 0.001\n",
      "[8,   420] loss: 0.001\n",
      "[8,   440] loss: 0.001\n",
      "[8,   460] loss: 0.001\n",
      "[8,   480] loss: 0.001\n",
      "[8,   500] loss: 0.001\n",
      "[8,   520] loss: 0.001\n",
      "[8,   540] loss: 0.001\n",
      "[8,   560] loss: 0.001\n",
      "[8,   580] loss: 0.001\n",
      "[8,   600] loss: 0.001\n",
      "[8,   620] loss: 0.001\n",
      "[8,   640] loss: 0.001\n",
      "[8,   660] loss: 0.001\n",
      "[8,   680] loss: 0.001\n",
      "[8,   700] loss: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   720] loss: 0.001\n",
      "[8,   740] loss: 0.001\n",
      "[8,   760] loss: 0.001\n",
      "[8,   780] loss: 0.001\n",
      "[8,   800] loss: 0.001\n",
      "[8,   820] loss: 0.001\n",
      "[8,   840] loss: 0.001\n",
      "[8,   860] loss: 0.001\n",
      "[8,   880] loss: 0.001\n",
      "[8,   900] loss: 0.001\n",
      "[8,   920] loss: 0.001\n",
      "[9,    20] loss: 0.001\n",
      "[9,    40] loss: 0.001\n",
      "[9,    60] loss: 0.001\n",
      "[9,    80] loss: 0.001\n",
      "[9,   100] loss: 0.001\n",
      "[9,   120] loss: 0.001\n",
      "[9,   140] loss: 0.001\n",
      "[9,   160] loss: 0.001\n",
      "[9,   180] loss: 0.001\n",
      "[9,   200] loss: 0.001\n",
      "[9,   220] loss: 0.001\n",
      "[9,   240] loss: 0.001\n",
      "[9,   260] loss: 0.001\n",
      "[9,   280] loss: 0.001\n",
      "[9,   300] loss: 0.001\n",
      "[9,   320] loss: 0.001\n",
      "[9,   340] loss: 0.001\n",
      "[9,   360] loss: 0.001\n",
      "[9,   380] loss: 0.001\n",
      "[9,   400] loss: 0.001\n",
      "[9,   420] loss: 0.001\n",
      "[9,   440] loss: 0.001\n",
      "[9,   460] loss: 0.001\n",
      "[9,   480] loss: 0.001\n",
      "[9,   500] loss: 0.001\n",
      "[9,   520] loss: 0.001\n",
      "[9,   540] loss: 0.001\n",
      "[9,   560] loss: 0.001\n",
      "[9,   580] loss: 0.001\n",
      "[9,   600] loss: 0.001\n",
      "[9,   620] loss: 0.001\n",
      "[9,   640] loss: 0.001\n",
      "[9,   660] loss: 0.001\n",
      "[9,   680] loss: 0.001\n",
      "[9,   700] loss: 0.001\n",
      "[9,   720] loss: 0.001\n",
      "[9,   740] loss: 0.001\n",
      "[9,   760] loss: 0.001\n",
      "[9,   780] loss: 0.001\n",
      "[9,   800] loss: 0.001\n",
      "[9,   820] loss: 0.001\n",
      "[9,   840] loss: 0.001\n",
      "[9,   860] loss: 0.001\n",
      "[9,   880] loss: 0.001\n",
      "[9,   900] loss: 0.001\n",
      "[9,   920] loss: 0.001\n",
      "[10,    20] loss: 0.001\n",
      "[10,    40] loss: 0.001\n",
      "[10,    60] loss: 0.001\n",
      "[10,    80] loss: 0.001\n",
      "[10,   100] loss: 0.001\n",
      "[10,   120] loss: 0.001\n",
      "[10,   140] loss: 0.001\n",
      "[10,   160] loss: 0.001\n",
      "[10,   180] loss: 0.001\n",
      "[10,   200] loss: 0.001\n",
      "[10,   220] loss: 0.001\n",
      "[10,   240] loss: 0.001\n",
      "[10,   260] loss: 0.001\n",
      "[10,   280] loss: 0.001\n",
      "[10,   300] loss: 0.001\n",
      "[10,   320] loss: 0.001\n",
      "[10,   340] loss: 0.001\n",
      "[10,   360] loss: 0.001\n",
      "[10,   380] loss: 0.001\n",
      "[10,   400] loss: 0.001\n",
      "[10,   420] loss: 0.001\n",
      "[10,   440] loss: 0.001\n",
      "[10,   460] loss: 0.001\n",
      "[10,   480] loss: 0.001\n",
      "[10,   500] loss: 0.001\n",
      "[10,   520] loss: 0.001\n",
      "[10,   540] loss: 0.001\n",
      "[10,   560] loss: 0.001\n",
      "[10,   580] loss: 0.001\n",
      "[10,   600] loss: 0.001\n",
      "[10,   620] loss: 0.001\n",
      "[10,   640] loss: 0.001\n",
      "[10,   660] loss: 0.001\n",
      "[10,   680] loss: 0.001\n",
      "[10,   700] loss: 0.001\n",
      "[10,   720] loss: 0.001\n",
      "[10,   740] loss: 0.001\n",
      "[10,   760] loss: 0.001\n",
      "[10,   780] loss: 0.001\n",
      "[10,   800] loss: 0.001\n",
      "[10,   820] loss: 0.001\n",
      "[10,   840] loss: 0.001\n",
      "[10,   860] loss: 0.001\n",
      "[10,   880] loss: 0.001\n",
      "[10,   900] loss: 0.001\n",
      "[10,   920] loss: 0.001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        _, labels =  torch.max(labels,1)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.68312957 0.81526336 0.83833141\n",
      "  0.58255286 0.60377547 0.5        0.5        0.5        0.5\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.88464877 0.19347139 0.         0.         0.\n",
      "  0.         0.23922417 0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.93243919\n",
      "  0.18953479 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.93060361 0.5        0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.70832042 0.18379937 0.\n",
      "  0.         0.         0.         0.         0.86804306 0.91196463\n",
      "  0.         0.         0.9982699  0.5        0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.5        0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.86902474 0.         0.\n",
      "  0.         0.         0.         0.85143406 0.5        0.91292083\n",
      "  0.         0.         0.9982699  0.5        0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.5        0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.0129258  0.         0.\n",
      "  0.         0.0723491  0.85986159 0.5        0.5        0.97740095\n",
      "  0.         0.         0.9982699  0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.82562465 0.49218762 0.99593233\n",
      "  0.78555171 0.5        0.5        0.5        0.5        0.83833141\n",
      "  0.         0.         0.9982699  0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.14432141\n",
      "  0.         0.         0.9982699  0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.73683199 0.59676278 0.58255286 0.59676278 0.\n",
      "  0.         0.         0.54595156 0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.64455978 0.98578239\n",
      "  0.01846213 0.         0.         0.         0.         0.\n",
      "  0.         0.89830834 0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.         0.         0.5        0.5        0.5\n",
      "  0.5        0.5        0.57564015 0.9883045  0.         0.\n",
      "  0.         0.         0.05555556 0.         0.         0.\n",
      "  0.         0.65114187 0.58968858 0.5        0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.5\n",
      "  0.5        0.59002418 0.9750173  0.         0.         0.53100006\n",
      "  0.9977425  0.5        0.74249135 0.         0.         0.\n",
      "  0.         0.         0.93349481 0.60377547 0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.5\n",
      "  0.57535563 0.38195176 0.         0.         0.01557093 0.72022444\n",
      "  0.5        0.77602455 0.         0.         0.         0.46899994\n",
      "  0.04097655 0.         0.         0.00523901 0.99905482 0.9983358\n",
      "  0.97323337 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.54666593\n",
      "  0.36108204 0.         0.         0.78038447 0.73111111 0.5\n",
      "  0.98632897 0.         0.         0.         0.999721   0.5\n",
      "  0.69549404 0.9916263  0.09818531 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.79065744\n",
      "  0.         0.         0.9276509  0.74249135 0.98947328 0.0521111\n",
      "  0.         0.         0.5232526  0.85143406 0.5        0.5\n",
      "  0.5        0.5        0.5        0.91712884 0.01188114 0.01557093\n",
      "  0.95552478 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.55339485 0.54595156 0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.         0.02159938 0.66412149\n",
      "  0.90525952 0.56077662 0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.68441157\n",
      "  0.89474048 0.28642061 0.59676278 0.79570165 0.58968858 0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.5        0.5        0.5        0.5        0.5\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.5\n",
      "  0.5        0.5        0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_fuzzy[index][0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05098039, 0.09803922, 0.39215686, 0.47843137, 0.02745098,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12941176, 0.59215686, 0.81568627, 0.98823529,\n",
       "       0.98823529, 0.98823529, 0.57254902, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15686275, 0.59607843, 0.95686275,\n",
       "       0.98823529, 0.99215686, 0.87843137, 0.82745098, 0.98823529,\n",
       "       0.90980392, 0.15686275, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05882353, 0.59607843,\n",
       "       0.9372549 , 0.98823529, 0.98823529, 0.98823529, 0.84705882,\n",
       "       0.12156863, 0.14509804, 0.98823529, 0.98823529, 0.23529412,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.37647059, 0.98823529, 0.98823529, 0.98823529,\n",
       "       0.98823529, 0.85098039, 0.11372549, 0.        , 0.14509804,\n",
       "       0.98823529, 0.98823529, 0.23529412, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.70980392,\n",
       "       0.98823529, 0.98823529, 0.8627451 , 0.65490196, 0.11764706,\n",
       "       0.        , 0.        , 0.30196078, 0.98823529, 0.98823529,\n",
       "       0.23529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10196078, 0.50196078, 0.22745098,\n",
       "       0.08627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39215686, 0.98823529, 0.98823529, 0.23529412, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.61568627, 0.98823529,\n",
       "       0.98823529, 0.23529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.43137255, 0.4745098 , 0.47843137,\n",
       "       0.4745098 , 0.79215686, 0.98823529, 0.76078431, 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03921569, 0.20784314, 0.70196078,\n",
       "       0.99215686, 0.99215686, 1.        , 0.99215686, 0.99215686,\n",
       "       0.89411765, 0.1372549 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01960784, 0.21176471,\n",
       "       0.89019608, 0.98823529, 0.95294118, 0.89411765, 0.66666667,\n",
       "       0.94901961, 0.98823529, 0.98823529, 0.90588235, 0.45882353,\n",
       "       0.02352941, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02352941, 0.30588235, 0.98823529, 0.98823529, 0.49019608,\n",
       "       0.23137255, 0.        , 0.07058824, 0.81568627, 0.98823529,\n",
       "       0.98823529, 0.98823529, 0.98823529, 0.34117647, 0.02745098,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01960784, 0.52941176, 0.98823529,\n",
       "       0.98823529, 0.70588235, 0.0627451 , 0.        , 0.08235294,\n",
       "       0.79607843, 0.99215686, 0.96862745, 0.50588235, 0.67843137,\n",
       "       0.98823529, 0.98823529, 0.72156863, 0.25882353, 0.19215686,\n",
       "       0.19215686, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.53333333, 0.98823529, 0.94509804, 0.41568627, 0.06666667,\n",
       "       0.        , 0.20784314, 0.78431373, 0.98823529, 0.84705882,\n",
       "       0.25490196, 0.        , 0.05490196, 0.28235294, 0.63921569,\n",
       "       0.94509804, 0.98823529, 0.98823529, 0.8745098 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.41176471, 0.98823529, 0.94901961,\n",
       "       0.34509804, 0.07058824, 0.28627451, 0.66666667, 0.95686275,\n",
       "       0.98823529, 0.49411765, 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34901961, 0.70588235,\n",
       "       0.70588235, 0.14509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.90588235, 0.98823529, 0.96078431, 0.80392157, 0.84705882,\n",
       "       0.98823529, 0.98823529, 0.98823529, 0.48627451, 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.81176471, 0.98823529,\n",
       "       0.98823529, 0.98823529, 0.98823529, 0.69803922, 0.45490196,\n",
       "       0.14117647, 0.01568627, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05098039, 0.36470588, 0.56078431, 0.4745098 ,\n",
       "       0.09019608, 0.02352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
